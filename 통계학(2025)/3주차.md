# 통계학 3주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_3rd_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

2주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_3rd_TIL

### 2부. 데이터 분석 준비하기
### 08. 분석 프로젝트 준비 및 기획
### 09. 분석 환경 세팅하기



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | 🍽️      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      |  

<!-- 여기까진 그대로 둬 주세요-->

# 08. 분석 프로젝트 준비 및 기획

```
✅ 학습 목표 :
* 데이터 분석 프로세스를 설명할 수 있다.
* 비즈니스 문제를 정의할 때 주의할 점을 설명할 수 있다.
* 외부 데이터를 수집하는 방법에 대해 인식한다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 8.1 데이터 분석의 전체 프로세스 

#### 데이터 분석의 궁극적인 목표

* 의사결정 프로세스의 최적화 
* 효과적인 결정을 할 수 있도록 도움 주는 것 

* 과정 : 설계 단계 -> 분석 및 모델링 단계 -> 구축 및 활용 단계 

#### CRISP - DM 방법론 

* 비즈니스 이해 -> 데이터 이해 -> 데이터 준비 -> 모델링 -> 평가 -> 배포

#### SAS SEMMA 방법론

* Sampling(데이터 추출) -> Exploration(데이터 탐색) -> Modification(변수가공) -> Modeling(모델 구축) -> Assessment(모델 평가)

## 8.2 비즈니스 문제 정의와 분석 목적 도출 

* 채찍 효과 : 공급 사슬에서 단계적 수요의 증폭 현상을 표현하는 용어 

* MECE(Mutually Exclusive Collectively Exhaustive): 세부 정의들이 중복되지 않고 합쳤을 때 전체를 봤을 때는 빠진 것 없이 완전한 전체를 이루는 것 

## 8.3 분석 목적의 전환 

* 분석 프로젝트의 방향은 언제든 변경 가능 

* 분석 프로젝트를 수행하는 동안에는 실무자들 간의 커뮤니케이션 및 협력이 매우 중요 

## 8.4 도메인 지식 

* 정의 : 해당 업종에 대한 이해도를 의미 

## 8.5 외부 데이터 수집과 크롤링

* 많은 기업들이 보유하고 있는 데이터들의 부족한 부분을 보완하고자 외부 데이터를 수집하여 활용 

* 외부 데이터를 수집할 때는 분석 목적을 명확하게 정의하고, 다수의 경로를 통해 다양한 데이터를 한꺼번에 수집한 후 머신러닝 모델이나 분석 목적에 맞도록 통합, 가공 후 비즈니스에 활용 필요 



# 09. 분석 환경 세팅하기

```
✅ 학습 목표 :
* 데이터 분석의 전체적인 프로세스를 설명할 수 있다.
* 테이블 조인의 개념과 종류를 이해하고, 각 조인 방식의 차이를 구분하여 설명할 수 있다.
* ERD의 개념과 역할을 이해하고, 기본 구성 요소와 관계 유형을 설명할 수 있다.
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 9.1 어떤 데이터 분석 언어를 사용하는 것이 좋을까?

* R, PYTHON, SQL 

## 9.2 데이터 처리 프로세스 이해하기  

1. OLTP(On-Line Transaction Processing): 실시간으로 데이터를 트랜잭션 단위로 수집, 분류, 저장하는 시스템

2. DW(Data Warehouse): 말 그대로 데이터 창고와 같은 개념으로, 수집된 데이터를 사용자 관점에서 주제별로 통합하여 쉽게 원하는 데이터를 빼낼 수 있도록 저장해 놓은 통합 데이터베이스

3. DM(Data Mart): 사용자의 목적에 맞도록 가공된 일부의 데이터가 저장되는 곳

4. OLAP 

* ETL : 저장된 데이터를 사용자가 원하는 포멧으로 변형 후 이동시키는 작업 과정 

<br>
<br>

# 확인 문제

## 문제 1.

> **🧚 아래의 테이블을 조인한 결과를 출력하였습니다. 어떤 조인 방식을 사용했는지 맞춰보세요.**

> 사용한 테이블은 다음과 같습니다.

![TABLE1](https://github.com/ejejbb/Template/raw/main/File/2.6.PNG)|![TABLE2](https://github.com/ejejbb/Template/raw/main/File/2.7.PNG)
---|---|

> 보기: INNER, LEFT, RIGHT 조인

<!-- 테이블 조인의 종류를 이해하였는지 확인하기 위한 문제입니다. 각 테이블이 어떤 조인 방식을 이용하였을지 고민해보고 각 테이블 아래에 답을 작성해주세요.-->

### 1-1. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-1.PNG)
```
LEFT JOIN
```



### 1-2. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-3.PNG)
```
INNER JOIN
```

### 1-3. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-2.PNG)
```
RIGHT JOIN
```

### 🎉 수고하셨습니다.